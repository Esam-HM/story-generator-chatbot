{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import traceback\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('ytu-ce-cosmos/turkish-gpt2-medium-350m-instruct-v0.1')\n",
    "tokenizerBase = GPT2Tokenizer.from_pretrained('ytu-ce-cosmos/turkish-gpt2')\n",
    "special_tokens_dict = {\n",
    "    \"bos_token\": \"<BOS>\",\n",
    "    \"eos_token\": \"<EOS>\",\n",
    "    \"pad_token\": \"<PAD>\",\n",
    "    \"additional_special_tokens\": [\"<Title>\",\"<EndTitle>\"]\n",
    "    }\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "tokenizerBase.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "modelMed = GPT2LMHeadModel.from_pretrained('./Medium')\n",
    "modelBase = GPT2LMHeadModel.from_pretrained('./Base')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelMed.to(device)\n",
    "modelBase.to(device)\n",
    "\n",
    "def generate_text_Medium(prompt, max_length=750):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    outputs = modelMed.generate(inputs, max_length=max_length, num_return_sequences=1,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            repetition_penalty=1.2,\n",
    "                            early_stopping= True ,\n",
    "                            num_beams = 3)\n",
    "    \n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return text\n",
    "\n",
    "def generate_text_Base(prompt, max_length=750):\n",
    "    inputs = tokenizerBase.encode(prompt, return_tensors='pt').to(device)\n",
    "    \n",
    "    outputs = modelBase.generate(inputs, max_length=max_length, num_return_sequences=1,\n",
    "                            eos_token_id=tokenizerBase.eos_token_id,\n",
    "                            repetition_penalty=1.2,\n",
    "                            early_stopping= True ,\n",
    "                            num_beams = 3)\n",
    "    \n",
    "    text = tokenizerBase.decode(outputs[0], skip_special_tokens=True)\n",
    "    return text\n",
    "\n",
    "@app.route('/api', methods=['POST'])\n",
    "def api():\n",
    "    if request.method == 'POST':\n",
    "        data = request.get_json()\n",
    "        title = data.get('title')\n",
    "        modelType = data.get('model')\n",
    "        print(modelType)\n",
    "        if modelType == \"Medium\":\n",
    "            text = generate_text_Medium(\"<BOS> <Title> \"+title + \" <EndTitle>\",750)\n",
    "        else:\n",
    "            text = generate_text_Base(\"<BOS> <Title> \"+title + \" <EndTitle>\",750)\n",
    "        text = text.replace(title,\"\")\n",
    "        return jsonify(text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(host='localhost', port=5000, debug=False)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
